{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IcBBCVOWQDol",
        "PMYKQbplHpBx",
        "WG-jLebFE6d4"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP_2022/blob/main/02-Machine-Learning/notebooks/11-Regresion-Logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "rfXeNiZcRgDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión Logística\n",
        "\n",
        "En esta notebook usaremos la implementación de scikit-learn de la regresión logística. Primero veremos dos ejemplos didacticos para entender el funcionamiento del clasificador. Después, resolveremos un ejemplo usando el conjunto de datos de dígitos escritos a mano."
      ],
      "metadata": {
        "id": "b3V19FWkQQcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1(a)\n",
        "\n",
        "Un ejemplo con datos unidimensionales"
      ],
      "metadata": {
        "id": "IcBBCVOWQDol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_blobs(n_samples=10,\n",
        "                  n_features=1,\n",
        "                  centers=2,\n",
        "                  random_state=17)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(x=X,y=[0 for x in X],c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oYpsW80AQHaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X,y)\n",
        "\n",
        "probs = lr.predict_proba(X)\n",
        "probs[:,1]"
      ],
      "metadata": {
        "id": "oHKBV84fRJNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "\n",
        "def f(x):\n",
        "    return w0+w1*x\n",
        "\n",
        "def plog(x):\n",
        "    return 1/(1+e**(-f(x)))\n",
        "\n",
        "w0, w1 = lr.intercept_, lr.coef_[0]\n",
        "xmin, xmax = np.min(X), np.max(X)\n",
        "xs = np.linspace(xmin,xmax,100)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(x=X,y=[0 for x in X],c=y,s=85)\n",
        "plt.plot(xs,[plog(x) for x in xs],color='black')\n",
        "plt.scatter(x=X,y=probs[:,1],c=y,marker='+',s=85)\n",
        "plt.axhline(y=0.5,color='gray',linestyle='--')\n",
        "plt.yticks([0,0.5,1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FfXe-PB-RZM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1(b)\n",
        "\n",
        "En este ejemplo, clasificamos un pequeño conjunto de datos en 2 dimensiones"
      ],
      "metadata": {
        "id": "PMYKQbplHpBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_blobs(n_samples=10,\n",
        "                  n_features=2,\n",
        "                  centers=2,\n",
        "                  random_state=20)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1],c=y,s=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rs4oVeTnSgDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X,y)"
      ],
      "metadata": {
        "id": "Koz4sdpG9r2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos acceder al intercepto y los coeficientes"
      ],
      "metadata": {
        "id": "zAOkjEGnFvrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w0, w1, w2 = lr.intercept_, lr.coef_[0,0], lr.coef_[0,1]"
      ],
      "metadata": {
        "id": "Umn99YKmHDkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos las probabilidades"
      ],
      "metadata": {
        "id": "JgdQDRejF1i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = lr.predict_proba(X)\n",
        "probs"
      ],
      "metadata": {
        "id": "6l25CLi0F3NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafiquemos y visualicemos las probabilidades"
      ],
      "metadata": {
        "id": "Nm9b-ViKF7tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import e\n",
        "from matplotlib import cm\n",
        "from itertools import product\n",
        "\n",
        "def f(x,y):\n",
        "    return w0+w1*x+w2*y\n",
        "\n",
        "def plog(x,y):\n",
        "    return 1/(1+e**(-f(x,y)))\n",
        "\n",
        "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"},dpi=300)\n",
        "\n",
        "xmin, xmax = np.min(X[:,0]), np.max(X[:,0])\n",
        "ymin, ymax = np.min(X[:,1]), np.max(X[:,1])\n",
        "\n",
        "xs = np.linspace(xmin, xmax,50)\n",
        "ys = np.linspace(ymin, ymax, 50)\n",
        "Xs, Ys = np.meshgrid(xs, ys)\n",
        "Z = np.array([plog(x,y) for x,y in zip(Xs,Ys)])\n",
        "\n",
        "surf = ax.plot_surface(Xs, Ys, Z, cmap=cm.coolwarm,\n",
        "                       linewidth=0, antialiased=False)\n",
        "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "ax.plot_surface(Xs, Ys, 0.5+np.zeros_like(Z),\n",
        "                       linewidth=0, antialiased=False,alpha=0.4,color='gray')\n",
        "ax.scatter(X[:,0],X[:,1],[0 for x in X],c=y,s=60)\n",
        "ax.scatter(X[:,0],X[:,1],[plog(x[0],x[1]) for x in X],c='black',s=60,marker='x')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0aUtgr8j-I_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2(a)\n",
        "\n",
        "En el siguiente ejemplo vemos cómo generar fronteras de decisión más complejas."
      ],
      "metadata": {
        "id": "nOJSxbuHAG2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/02-Machine-Learning/data/binary-classification-data.csv'\n",
        "df = pd.read_csv(url,header=None)\n",
        "df"
      ],
      "metadata": {
        "id": "OqWvQhFtAF80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observemos los datos"
      ],
      "metadata": {
        "id": "LkkaTp2VELqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = df.iloc[:,:-1].values\n",
        "y = df.iloc[:,-1].values\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[:,0],X[:,1],c=y,s=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w6J2M-2ZAXJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Funciones para graficas las fronteras de decisión\n",
        "import numpy as np\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    '''\n",
        "    función para hacer la malla de puntos para colorear las regiones de decisión,\n",
        "    la malla de puntos abarca la región donde se encuentran los puntos (x,y)\n",
        "    'h' es el tamaño de paso\n",
        "    '''\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aLEw1UazBFGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos una regresión logística con los parámetros por default y vemos su accuracy en el conjunto de entrenamiento."
      ],
      "metadata": {
        "id": "MpVXzmrJEUzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X,y)\n",
        "lr.score(X,y)"
      ],
      "metadata": {
        "id": "YAa-YvQ2AsRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos una regresión logística con polinomial features y vemos su accuracy en el conjunto de entrenamiento"
      ],
      "metadata": {
        "id": "lMtO_fr7Ei8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "p_feats = PolynomialFeatures(2,include_bias=False)\n",
        "log_reg = LogisticRegression(penalty='l2', C=1, solver='newton-cholesky')\n",
        "\n",
        "pl = Pipeline([('pf',p_feats),\n",
        "               ('clf',log_reg)])\n",
        "pl.fit(X,y)\n",
        "pl.score(X,y)"
      ],
      "metadata": {
        "id": "S0YYNWo-CSQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx, yy = make_meshgrid(X[:,0], X[:,1])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, lr, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Regresión Logística')\n",
        "\n",
        "plot_contours(ax2, pl, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(X[:,0], X[:,1], c=y, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Regresión Logística con Polinomial Features')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DfUVPwd0BKx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2(b)\n",
        "\n",
        "En este ejemplo veremos el efecto de la regularización como herramienta para prevenir el *overfitting*. Veremos un dataset con muchas features y varias de ellas correlacionadas."
      ],
      "metadata": {
        "id": "WG-jLebFE6d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# X, y = make_classification(n_samples=300,\n",
        "#                            n_features=60,\n",
        "#                            n_informative=20,\n",
        "#                            n_repeated=3,\n",
        "#                            n_redundant=20,\n",
        "#                            n_classes=2,\n",
        "#                            n_clusters_per_class=3,\n",
        "#                            class_sep = 0.5,\n",
        "#                            random_state=49)\n",
        "\n",
        "X, y = make_classification(n_samples=500,\n",
        "                           n_features=100,\n",
        "                           n_informative=20,\n",
        "                           n_repeated=3,\n",
        "                           n_redundant=20,\n",
        "                           n_classes=2,\n",
        "                           class_sep = 0.5,\n",
        "                           random_state=57)"
      ],
      "metadata": {
        "id": "Vz9hERUdFDLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.75,random_state=1001)"
      ],
      "metadata": {
        "id": "DNmbURE5OhMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realicemos el entrenamiento. El rendimiento parece ser bueno en el conjunto de entrenamiento pero en el conjunto de prueba es malo. **Esta es una señal de overfitting**."
      ],
      "metadata": {
        "id": "bo-jhCyjPkwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(penalty=None)\n",
        "lr.fit(X_train,y_train)\n",
        "print(f\"Training score: {lr.score(X_train,y_train)}\")\n",
        "print(f\"Test score: {lr.score(X_test,y_test)}\")"
      ],
      "metadata": {
        "id": "mNR7fsqLFXwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "normas = np.array([np.linalg.norm(x) for x in lr.coef_[0]])\n",
        "\n",
        "plt.figure()\n",
        "sns.histplot(normas)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dlSAVhe6GwmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos un clasificador con regularización"
      ],
      "metadata": {
        "id": "ARD6dohrEf9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr2 = LogisticRegression(C=0.1,penalty='l1',solver='liblinear')\n",
        "lr2.fit(X_train,y_train)\n",
        "print(f\"Training score: {lr2.score(X_train,y_train)}\")\n",
        "print(f\"Test score: {lr2.score(X_test,y_test)}\")"
      ],
      "metadata": {
        "id": "lHLUcIizFadi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "normas = np.array([np.linalg.norm(x) for x in lr2.coef_[0]])\n",
        "\n",
        "plt.figure()\n",
        "sns.histplot(normas)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AcAkl2JpGzKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que hay varios coeficientes que son exactamente cero. Observar que el número es parecido al número de features redundantes + número de features repetidas"
      ],
      "metadata": {
        "id": "vIekmN0jQj2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coefs = lr2.coef_\n",
        "num_zeros = coefs[coefs==0].shape[0]\n",
        "print(f\"Número de coeficientes = 0: {num_zeros}\")"
      ],
      "metadata": {
        "id": "IysWsZNVJyWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el score ROC-AUC"
      ],
      "metadata": {
        "id": "5s6usJcrEkc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_pred_probs = lr2.predict_proba(X_test)\n",
        "score = roc_auc_score(y_test, y_pred_probs[:,1])\n",
        "from sklearn.metrics import roc_auc_scoreprint(f\"ROC-AUC score: {score}\")"
      ],
      "metadata": {
        "id": "A_1SMbz1EoGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:,1])\n",
        "\n",
        "plt.figure()\n",
        "plt.suptitle(\"Curva ROC\") \n",
        "plt.plot(fpr,tpr,color='red')\n",
        "plt.plot([0,1],[0,1],linestyle='--',color='gray')\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zrim6QaRFXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 3"
      ],
      "metadata": {
        "id": "LEMdMkLuQGKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos el dataset de dígitos escritos a mano. Tenemos dos versiones:\n",
        "\n",
        "* Usando `keras`, es el dataset MNIST completo. Son 70,000 imágenes de $28\\times 28$, divididas en 60,000 de entrenamiento y 10,000 de prueba.\n",
        "* Usando `sklearn`, es una versión reducida. Son 1797 imágenes de $8\\times 8$.\n",
        "\n",
        "Por practicidad, usaremos la segunda opción."
      ],
      "metadata": {
        "id": "zTr3VB0m8i4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtJDTDJOQKXQ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "gNoodzVS82tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos el dataset"
      ],
      "metadata": {
        "id": "00M5Gbh99S5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target"
      ],
      "metadata": {
        "id": "fyDYWTPZCojo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "HDq_dRQV9Ap-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo se ve una instancia del conjunto de datos"
      ],
      "metadata": {
        "id": "6mi2f4UF-uHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[28]"
      ],
      "metadata": {
        "id": "WB2rc9-m-xMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[28].reshape(8,8)"
      ],
      "metadata": {
        "id": "1E9y9HwX-nHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos la división en entrenamiento y prueba."
      ],
      "metadata": {
        "id": "fWUaSnsE9VJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=128)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "t_1rKiyCC9UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiamos la forma, para que cada instancia sea un arreglo bidimensional"
      ],
      "metadata": {
        "id": "hIb6Gn4d9XlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_size = X_train.shape[0]\n",
        "test_size = X_test.shape[0]\n",
        "X_train = X_train.reshape(train_size,-1)\n",
        "X_test = X_test.reshape(test_size,-1)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "ULrYQTUzBCKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos algunas instancias de entrenamiento."
      ],
      "metadata": {
        "id": "VkSa9zAz-gt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7,2))\n",
        "for idx, (image, label) in enumerate(zip(X_train[:5], y_train[:5])):\n",
        "    plt.subplot(1, 5, idx + 1)\n",
        "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.title(label)"
      ],
      "metadata": {
        "id": "kdbuOPm5QfCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos la implementación de scikit-learn ([documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html))."
      ],
      "metadata": {
        "id": "Kk1WPJqkRk8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "d_NmqDxjQ4DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Realiza el entrenamiento de un módelo de Regresión Lineal y realiza las predicciones sobre el conjunto de prueba. Reporta las métricas de rendimiento (accuracy, recall, precision, f1-score) y la mátriz de confusión con el conjunto de prueba.\n",
        "\n",
        "Puedes usar los parámetros que gustes para el modelo."
      ],
      "metadata": {
        "id": "W8klQizkRUlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tu código\n",
        "'''"
      ],
      "metadata": {
        "id": "3rfi1u-gQYpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = lr.predict_proba(X_test)\n",
        "y_pred_probs.shape"
      ],
      "metadata": {
        "id": "bsBk1CLIA6j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos las probabilidades predichas y la etiqueta predicha"
      ],
      "metadata": {
        "id": "PflvKULISe5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred_probs[0])\n",
        "print(y_pred[0])"
      ],
      "metadata": {
        "id": "QidU_EliExcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como son probabilidades, la suma de las componentes es 1"
      ],
      "metadata": {
        "id": "bM7DKxy2Sij9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(y_pred_probs[0])"
      ],
      "metadata": {
        "id": "I5u5QDKFE5A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación cruzada\n",
        "\n",
        "Usemos validación cruzada para evaluar el entrenamiento de nuestro modelo, [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score)."
      ],
      "metadata": {
        "id": "Pzc7nPcNV44K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "scores = cross_val_score(lr, X_train, y_train, cv=5)"
      ],
      "metadata": {
        "id": "CS0mrtlRVUr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)\n",
        "print(np.mean(scores))"
      ],
      "metadata": {
        "id": "h6bnb-9sVgGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC-AUC Score\n",
        "\n",
        "Usaremos el area bajo la curva ROC como métrica de rendimiento del clasificador. Para esto necesitamos las probabilidades de las predicciones.\n",
        "\n",
        "Hay varias maneras de calcularlo:\n",
        "\n",
        "* Si el clasificador tiene un método `predict_proba`, usamos [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html).\n",
        "* Si no, usamos [RocCurveDisplay.from_estimator](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_estimator)"
      ],
      "metadata": {
        "id": "y0d0s-zfB6LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = lr.predict_proba(X_test)\n",
        "y_pred_probs.shape"
      ],
      "metadata": {
        "id": "-2Jc3wOJCBoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se trata de un problema multiclase podemos escoger el enfoque `ovr` (one-vs-rest) o `ovo` (one-vs-one). En este caso, no se puede graficar directamente la curva ROC."
      ],
      "metadata": {
        "id": "XTkP52QLDr_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "score = roc_auc_score(y_test, y_pred_probs,multi_class='ovr')\n",
        "print(f\"ROC-AUC score: {score}\")"
      ],
      "metadata": {
        "id": "u3V16eCtDFLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⭕ Práctica \"final\" de clasificación \n",
        "\n",
        "Retomar el dataset de la sesión pasada y probar los siguientes clasificadores:\n",
        "\n",
        "* Regresión Logística\n",
        "* SVM\n",
        "* Decision Tree\n",
        "* Random Forest\n",
        "\n",
        "Recuerda que hay algunos valores faltantes. \n",
        "\n",
        "1. ¿Qué clasificador tiene mejor rendimiento en este dataset? Para esto toma en cuenta el accuracy, F1-score y Cross-Validation (accuracy promedio) como métricas de rendimiento. \n",
        "\n",
        "Como siempre, puedes usar cualquier técnica de selección de features, escalamiento, regularización que desees."
      ],
      "metadata": {
        "id": "TY0QzMvrSpds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/02-Machine-Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "id": "l4aC-ulJE-sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay más clasificadores que es importante revisar. Con las herramientas que ya cuentas, ya puedes revisarlos por tu cuenta:\n",
        "\n",
        "* [K-nearest neighbors classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
        "* [Quadratic Discriminant Analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n",
        "* [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
        "* [Gaussian Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes)\n",
        "* ...\n",
        "\n",
        "[Más información](https://scikit-learn.org/stable/supervised_learning.html), [comparación](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)."
      ],
      "metadata": {
        "id": "IegLWougNyi_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aHaVyS3tOg_J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}