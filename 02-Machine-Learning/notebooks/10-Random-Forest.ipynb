{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP_2022/blob/main/02-Machine-Learning/notebooks/10-Random-Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "dgkZRymYrp13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n"
      ],
      "metadata": {
        "id": "oaGsnBPgxTTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El conjunto de datos"
      ],
      "metadata": {
        "id": "4-g_FnWiZxX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este dataset fue creado por el *National Institute of Diabetes and Digestive and Kidney Diseases* de Estados Unidos. El objetivo del dataset es predecir el diagnostico de cuándo un paciente tiene diabetes o no, basado en ciertas mediciones incluidas en el dataset. Varias restricciones fueron usadas en la selección de estas instancias para filtrar el dataset. En particular, se trata pacientes femeninas de al menos 21 años de edad pertenecientes al grupo indígena Pima de Arizona.\n",
        "\n",
        "Las variables incluidas son el numero de embarazos la paciente ha tenido, su BMI, nivel de insulina, edad, entre otras.\n",
        "\n",
        "El dataset se encuentra en https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database."
      ],
      "metadata": {
        "id": "ZICZK2UbQAF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://github.com/DCDPUAEM/DCDP/raw/main/02-Machine-Learning/data/diabetes.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df"
      ],
      "metadata": {
        "id": "bRn2dKBAnE1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento y Entrenamiento"
      ],
      "metadata": {
        "id": "U68d7c7OZ05k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Definimos las features\n",
        "feature_cols = df.columns.to_list()\n",
        "\n",
        "X = df[feature_cols].values    # Features\n",
        "y = df['label'].values         # Target variable"
      ],
      "metadata": {
        "id": "7lxPMBG3efOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7) # 70% training and 30% test\n",
        "\n",
        "clf = RandomForestClassifier(n_jobs=-1) \n",
        "\n",
        "clf = clf.fit(X_train,y_train)  \n",
        "y_pred = clf.predict(X_test)    # Predecimos usando el conjunto de prueba"
      ],
      "metadata": {
        "id": "7atm7aq0lNbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo lo hizo en el conjunto de prueba?"
      ],
      "metadata": {
        "id": "4eSid5xOC5Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "y_train_pred = clf.predict(X_train)\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_train,y_train_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_train,y_train_pred),3)}\")\n",
        "print(f\"Precision: {round(precision_score(y_train,y_train_pred),3)}\")\n",
        "\n",
        "print(f\"Accuracy, usando el método score: {clf.score(X_train,y_train)}\")"
      ],
      "metadata": {
        "id": "GPfNqsEdC8mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "jxZytL2YZ5L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test,y_pred),3)}\")\n",
        "print(f\"Recall: {round(recall_score(y_test,y_pred),5)}\")\n",
        "print(f\"Precision: {round(precision_score(y_test,y_pred),3)}\")\n",
        "\n",
        "target_labels = ['no diabetes','diabetes']\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "s_cm = sns.heatmap(cm,cmap='plasma',annot=True, fmt='g',\n",
        "            xticklabels=target_labels,\n",
        "            yticklabels=target_labels)\n",
        "s_cm.set(xlabel='Predicted',ylabel='Real')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GrZ5YGFglSoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos obtener la importancia de las features de acuerdo a la reducción de impureza de los nodos donde participan. "
      ],
      "metadata": {
        "id": "RF2S2joxHEMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "importances = pd.DataFrame({'feature':feature_cols,'importancia':np.round(clf.feature_importances_,3)})\n",
        "importances.sort_values(by='importancia',ascending=False,inplace=True)\n",
        "importances.set_index('feature')"
      ],
      "metadata": {
        "id": "bs4t4_9Khaum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploración del random forest\n",
        "\n",
        "Podemos explorar el conjunto de árboles de decisión construidos por el random forest mediante la lista `estimators_`. Cada elemento de esta lista es un árbol de decisión como los que usamos la sesión pasada."
      ],
      "metadata": {
        "id": "AjlyNZj6ZrkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cuántos árboles se usaron?"
      ],
      "metadata": {
        "id": "00vrUdMfrl26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de árboles: {len(clf.estimators_)}\")"
      ],
      "metadata": {
        "id": "JO9UAIcNlWyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analicemos la predicción para un elemento arbitrario de X_test"
      ],
      "metadata": {
        "id": "mv1KwTWjaxRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "idx0 = 37\n",
        "new_x = X_test[idx0]\n",
        "print(f\"Etiqueta real: {y_test[idx0]}, Preddición: {y_pred[idx0]}\")\n",
        "\n",
        "predicciones = []\n",
        "for dt in clf.estimators_:\n",
        "    predicted_label = int(dt.predict([X_test[idx0]])[0])  # No podemos pasar sólo un renglón de X_test, tiene que ser una matriz, por lo que pasamos una matriz de tamaño 1 x num_features\n",
        "    predicciones.append(predicted_label)\n",
        "\n",
        "# #Usando list comprehension:\n",
        "# predicciones = [int(dt.predict([X_test[idx0]])[0]) for dt in clf.estimators_] \n",
        "\n",
        "print(f\"Las primeras 10 predicciones: {predicciones[:10]}\")\n",
        "\n",
        "# ---- Contamos cuántos votos tuvo cada etiqueta por parte del bosque ----\n",
        "\n",
        "zeros = np.where(np.array(predicciones)==0)[0]\n",
        "ones = np.where(np.array(predicciones)==1)[0]\n",
        "\n",
        "print(f\"{zeros.shape[0]} árboles que predijeron la etiqueta 0:\\n{zeros}\\n\")\n",
        "print(f\"{ones.shape[0]} Árboles que predijeron la etiqueta 1:\\n{ones}\\n\")"
      ],
      "metadata": {
        "id": "pwzu-RjOY0v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploremos un árbol arbitrario del ensamble. "
      ],
      "metadata": {
        "id": "2MMyUH5VQMdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "dt = clf.estimators_[1]\n",
        "\n",
        "print(f\"Profundidad del árbol: {dt.get_depth()}\")\n",
        "print(f\"Número de hojas del árbol: {dt.get_n_leaves()}\")\n",
        "\n",
        "text_representation = tree.export_text(decision_tree=dt,\n",
        "                                    feature_names=feature_cols)\n",
        "# print(text_representation)"
      ],
      "metadata": {
        "id": "VnXR9ksKdIQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploremos estadísticamente todos los árboles individuales del ensamble"
      ],
      "metadata": {
        "id": "L0Q3JpGWQREF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "profundidades = [dt.get_depth() for dt in clf.estimators_]\n",
        "hojas = [dt.get_n_leaves() for dt in clf.estimators_]\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(9,5),sharey=True)\n",
        "axs[0].set_title(\"Historgrama de profundidades\")\n",
        "sns.histplot(profundidades,ax=axs[0])\n",
        "axs[1].set_title(\"Historgrama de hojas\")\n",
        "sns.histplot(hojas,ax=axs[1])\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "2hPIeim_OtEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparación con el DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "GJB1VDH7GrkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ **Práctica**:\n",
        "\n",
        "1. Encuentra el árbol del ensamble con el mejor rendimiento, respecto al accuracy, \n",
        "2. Vamos a compararlo con el mejor árbol de decisión de la práctica pasada: \n",
        "    * Compara la profundidad y número de hojas de ambos.\n",
        "    * Compara los rendimientos de ambos-\n",
        "    * ¿Puedes compararlos en las otras métricas de rendimiento? Precision, Recall, F1-score."
      ],
      "metadata": {
        "id": "cZd0nZz6Q2o9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZV_vPm1sR0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}