{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DCDPUAEM/DCDP/blob/main/02-Machine-Learning/notebooks/06-SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\n",
        "\n",
        "En esta notebook mostraremos el uso del clasificador **SVM** (Support Vector Machine). Realizaremos un ejemplo con datos artificiales, con fines didácticos, y un ejemplo más grande, con datos reales.\n",
        "\n",
        "Usaremos la implementación de sklearn, llamada [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (Support Vector Classifier)"
      ],
      "metadata": {
        "id": "vmWhZfIxi6yU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1"
      ],
      "metadata": {
        "id": "UlqlbDHkTIsl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "glVe2E6ySpTP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones que necesitamos para graficar las fronteras de decisión"
      ],
      "metadata": {
        "id": "8cxOlJX_il7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_meshgrid(x, y, h=.02):\n",
        "    '''\n",
        "    función para hacer la malla de puntos para colorear las regiones de decisión,\n",
        "    la malla de puntos abarca la región donde se encuentran los puntos (x,y)\n",
        "    'h' es el tamaño de paso\n",
        "    '''\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out"
      ],
      "metadata": {
        "id": "DFox_ShDikzl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### El conjunto de datos"
      ],
      "metadata": {
        "id": "awsozxk0i4e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un conjunto de datos con una condición XOR"
      ],
      "metadata": {
        "id": "iX00M-qDi1zU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDNOtk2FTRDv"
      },
      "outputs": [],
      "source": [
        "np.random.seed(17) # Fijamos un seed para la reproducibilidad de resultados\n",
        "\n",
        "X = np.random.randn(1000, 2)\n",
        "Y = np.array([int(np.logical_xor(x[0] > 0, x[1] > 0)) for x in X])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[Y==0, 0], X[Y==0, 1], s=20, color='blue', label='Clase 0')\n",
        "plt.scatter(X[Y==1, 0], X[Y==1, 1], s=20, color='red',label='Clase 1')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos el conjunto de datos en train y test."
      ],
      "metadata": {
        "id": "Jy64NizLi95C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7-Hi2BmTUrd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2023)\n",
        "\n",
        "print(f\"X Train: {x_train.shape}\")\n",
        "print(f\"X Test: {x_test.shape}\")\n",
        "print(f\"Y Train: {y_train.shape}\")\n",
        "print(f\"Y Test: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEmnVOw6XJqq"
      },
      "source": [
        "### Clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SVM lineal\n",
        "\n",
        "Entrenemos el clasificador usando el kernel lineal. Observar que, por default, $C=1$."
      ],
      "metadata": {
        "id": "MLnixjtrjGoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt_JmIokV0xU"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observemos el accuracy en el conjunto de entrenamiento y prueba. En este caso, el método `score` de la clase `SVC` calcula el accuracy."
      ],
      "metadata": {
        "id": "ccEI8ng4glyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training mean accuracy: {round(clf.score(x_train, y_train),3)}\")\n",
        "print(f\"Test mean accuracy: {round(clf.score(x_test, y_test),3)}\")"
      ],
      "metadata": {
        "id": "jZMNw4GybN9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observemos la frontera de decisión calculada por el clasificador y los conjuntos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "qI_ajLA3kp_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "  \n",
        "fig, (ax1, ax2) = plt.subplots(1,2,dpi=100,figsize=(10,4)) # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "\n",
        "fig.suptitle(\"Fronteras de decisión\")\n",
        "\n",
        "plot_contours(ax1, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax1.scatter(x_train[:,0], x_train[:,1], c=y_train, cmap=plt.cm.coolwarm, s=20)\n",
        "ax1.set_xticks(())\n",
        "ax1.set_yticks(())\n",
        "ax1.set_title('Conjunto de entrenamiento')\n",
        "\n",
        "plot_contours(ax2, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax2.scatter(x_test[:,0], x_test[:,1], c=y_test, cmap=plt.cm.coolwarm, s=20)\n",
        "ax2.set_xticks(())\n",
        "ax2.set_yticks(())\n",
        "ax2.set_title('Conjunto de prueba')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YGTC1EmOh_nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ⭕ Probar otros kernels\n",
        "\n",
        "Con los mismos conjuntos de prueba y entrenamiento:\n",
        "\n",
        "1. Repetir el experimento de clasificación de arriba, usando otros kernels.\n",
        "2. En cada caso que pruebes grafica los puntos (los de prueba) y la frontera de decisión.\n",
        "3. En cada caso, reporta el valor de accuracy y recall, usando el conjunto de prueba solamente.\n",
        "\n",
        "**¿Qué kernel parece dar mejor resultado?**"
      ],
      "metadata": {
        "id": "EGMoIZhmsUbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentación: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
      ],
      "metadata": {
        "id": "Yl7aeHt7sm1H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jY4JoakxsULC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* El kernel lineal es mejor para datos linealmente separables. Es una opción cuando el conjunto de datos es grande. \n",
        "* El kernel Gaussiano (RBF) tiende a dar buenos resultados cuando no se tiene información adicional sobre los datos.\n",
        "* Los kernels polinomiales tienden a dar buenos resultados cuando los datos de entrenamiento están normalizados.\n",
        "\n",
        "[El truco del kernel](https://www.geogebra.org/m/xawkavxe)"
      ],
      "metadata": {
        "id": "Vqs84jSTs43l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Prueba también con otros valores de `C` y repite los pasos de arriba, ¿qué efecto tiene el modificar este valor en la clasificación?"
      ],
      "metadata": {
        "id": "-nXR_1f3m4Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2-UV1uOnQyH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando gridsearch para encontrar los mejores parámetros"
      ],
      "metadata": {
        "id": "2AFz2eTyjT3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) toma un estimador (por ejemplo, SVM) y un conjunto de parámetros del estimador. Sobre estos parámetros hace una busqueda para encontrar la combinación de parámetros que da mejores resultados en el estimador. \n",
        "\n",
        "GridSearchCV tiene métodos “fit” y “score” method, entre otros. Es decir, no es necesario tomar los parámetros e introducirlos en el estimador."
      ],
      "metadata": {
        "id": "fC23ZQAg7EpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "lVkQd-v1Z4aV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra los mejores parámetros para el clasificador SVM utilizando grid search. Guíate por el desempeño en el set de entrenamiento y validación.\n",
        "\n",
        "Prueba los siguientes hyperparámetros.\n",
        "* kernel = linear, polynomial, rbf\n",
        "* C = 0.01, 0.1, 1.0, 10, 100\n",
        "* grado del polinomio = 1, 2, 3, 4 (solo para el kernel polinomial)\n",
        "* gamma = auto, scale:"
      ],
      "metadata": {
        "id": "5ymSFVzkcf03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los parámetros sobre los que se hará la busqueda"
      ],
      "metadata": {
        "id": "CJZKn4kxo7LH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fehVJTIZZEmP"
      },
      "outputs": [],
      "source": [
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ('linear', 'poly', 'rbf'),\n",
        "              'degree': [1, 2, 3, 4], 'gamma': ('auto', 'scale')}\n",
        "param_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos una busqueda sobre estos parámetros "
      ],
      "metadata": {
        "id": "j6-yzMJUI40z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_mFhIYkaG_y"
      },
      "outputs": [],
      "source": [
        "clf = SVC()\n",
        "gs = GridSearchCV(clf, param_grid)\n",
        "gs.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los mejores hiper-parámetros"
      ],
      "metadata": {
        "id": "OntcfhwVrWgt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgCYpURZbCH2"
      },
      "outputs": [],
      "source": [
        "print(f\"Best score: {gs.best_score_:.4f}\")\n",
        "print(f\"Best params: {gs.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definamos un clasificador SVM con estos mejores hiperparámetros"
      ],
      "metadata": {
        "id": "0n2iAE_IrbCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jclaEUreczue"
      },
      "outputs": [],
      "source": [
        "best_svm = SVC(C=100, kernel='poly', degree=2, gamma='auto')\n",
        "best_svm.fit(x_train, y_train)\n",
        "\n",
        "print(f\"Train mean accuracy: {best_svm.score(x_train, y_train):6.4f}\")\n",
        "print(f\"Test mean accuracy: {best_svm.score(x_test, y_test):6.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos la frontera de decisión"
      ],
      "metadata": {
        "id": "cyE6AWhdh1OV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTSvVYqTdEwM"
      },
      "outputs": [],
      "source": [
        "xx, yy = make_meshgrid(X[:,0], X[:,1]) # Hacemos el grid para graficar las regiones\n",
        "\n",
        "fig, ax = plt.subplots(dpi=100)  # El parámetro dpi especifíca los puntos por pulgada (DPI) de la imagen\n",
        "plot_contours(ax, best_svm, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X[:,0], X[:,1], c=Y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title('Frontera de decisión del SVM')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparando el SVM lineal con el OLS (clasificador lineal)"
      ],
      "metadata": {
        "id": "fyhJ9XBnZCTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio vamos a comparar la clasificación y la frontera de decisión del clasificador de la sesión anterior (discriminante lineal OLS) con el SVM con kernel lineal.\n",
        "\n",
        "Para esto, vamos a usar ambos clasificadores en el mismo conjunto de datos. Después, compararemos la frontera de decisión."
      ],
      "metadata": {
        "id": "GyBLYOZ5ZKb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que el clasificador lo implementamos como una clase, podemos usarlo en esta notebook directamente. Hay dos maneras de hacerlo:\n",
        "\n",
        "* Copiando el código y definiendo la clase otra vez:\n",
        "* Descargando el archivo desde github:"
      ],
      "metadata": {
        "id": "qhjvxInbCZdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/DCDPUAEM/DCDP/main/02-Machine-Learning/data/clasificador_lineal.py\"\n",
        "!wget --no-cache --backups=1 {url}"
      ],
      "metadata": {
        "id": "caLo57ZRsZa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya está copiado en la misma carpeta donde estamos trabajando por lo que ya lo podemos importar directamente"
      ],
      "metadata": {
        "id": "P72hCNryCnxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from clasificador_lineal import LeastSquaresClassifier"
      ],
      "metadata": {
        "id": "96ypeu4tZiYI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el conjunto de datos, usaremos un dataset de scikit-learn:"
      ],
      "metadata": {
        "id": "-dxo2D_2C-_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "x_train, y_train = make_moons(n_samples = 120, random_state=89, noise=0.1)\n",
        "\n",
        "#--- Lo graficamos para verlo ---\n",
        "plt.figure()\n",
        "plt.scatter(x_train[:,0], x_train[:,1], c=y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "35_M3k2NEbua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Realiza la clasificación usando el clasificador OLS y grafica la frontera de decisión.\n",
        "\n",
        "Puedes usar el código para clasificar y graficar que usamos en la sesión anterior"
      ],
      "metadata": {
        "id": "fvRzxc_GMfO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "x1_test, x2_test = np.meshgrid(np.linspace(-2, 2.5, 100), np.linspace(-1, 1.5, 100))\n",
        "x_test = np.array([x1_test, x2_test]).reshape(2, -1).T\n",
        "\n",
        "features = PolynomialFeatures(1)\n",
        "X_train = features.fit_transform(x_train)\n",
        "X_test = features.fit_transform(x_test)\n",
        "\n",
        "#------ COMPLETAR ------\n",
        "modelo = LeastSquaresClassifier()   \n",
        "modelo.fit(X_train,y_train)          \n",
        "y_ols = modelo.clasifica(X_test)\n",
        "#----------------------\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)\n",
        "plt.contour(x1_test, x2_test, y_ols.reshape(100, 100))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qbcn1VCtC4Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Ahora, usemos SVM lineal\n",
        "\n",
        "Realiza la clasificación en el mismo dataset, usando SVM con kernel lineal y grafica la frontera de decisión. Puedes usar el código para clasificar y graficar que usamos anteriormente."
      ],
      "metadata": {
        "id": "vv8GUSe4NTzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1_test, x2_test = np.meshgrid(np.linspace(-2, 2.5, 100), np.linspace(-1, 1.5, 100))\n",
        "x_test = np.array([x1_test, x2_test]).reshape(2, -1).T\n",
        "\n",
        "#------ COMPLETAR ------\n",
        "lin_svm = SVC(kernel='linear')\n",
        "lin_svm.fit(x_train, y_train)\n",
        "y_svm = lin_svm.predict(x_test)\n",
        "#----------------------\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)\n",
        "plt.contour(x1_test, x2_test, y_svm.reshape(100, 100))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4BjC4BY7KHud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dibujamos ambas FD juntas. "
      ],
      "metadata": {
        "id": "9OeJaZ81enO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "#-----Dibujar los datos---------------------------------\n",
        "plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)\n",
        "#-----Dibujar X_test (la malla de fondo para ver las regiones ------------\n",
        "plt.contour(x1_test, x2_test, y_ols.reshape(100, 100),colors='green')\n",
        "plt.contour(x1_test, x2_test, y_svm.reshape(100, 100),colors='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b1AUz8FuXeMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar que no son la misma.\n",
        "\n",
        "🔵 ¿Por qué no?"
      ],
      "metadata": {
        "id": "I5CLQPSEPmmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2"
      ],
      "metadata": {
        "id": "QlT0ezfs_PwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este problema usaremos el datset de Kaggle.\n",
        "\n",
        "**Contexto**\n",
        "\n",
        "Los conjuntos de datos contienen transacciones realizadas con tarjetas de crédito en septiembre de 2013 por titulares de tarjetas europeos. Este conjunto de datos presenta transacciones que ocurrieron en dos días, donde tenemos 492 fraudes de 284,807 transacciones. El conjunto de datos está altamente desequilibrado, la clase positiva (fraudes) representa el 0.172% de todas las transacciones.\n",
        "\n",
        "Contiene solo variables de entrada numéricas que son el resultado de una transformación PCA. Desafortunadamente, debido a problemas de confidencialidad, no se pueden obtener las características originales y más información de fondo sobre los datos. Las características $V_1$, $V_2$, ..., $V_{28}$ son los componentes principales obtenidos con PCA, las únicas características que no se han transformado con PCA son 'Tiempo' y 'Cantidad'. La función 'Tiempo' contiene los segundos transcurridos entre cada transacción y la primera transacción en el conjunto de datos. La característica 'Cantidad' es la Cantidad de la transacción, esta característica se puede utilizar para el aprendizaje sensible al costo dependiente del ejemplo. La característica 'Clase' es la variable de respuesta y toma el valor 1 en caso de fraude y 0 en caso contrario.\n",
        "\n",
        "\n",
        "Recordemos las buenas prácticas del Machine Learning: https://scikit-learn.org/stable/common_pitfalls.html"
      ],
      "metadata": {
        "id": "-cCQM40V_dJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install > /dev/null subversion\n",
        "\n",
        "!svn checkout \"https://github.com/DCDPUAEM/DCDP/trunk/02-Machine-Learning/data/\""
      ],
      "metadata": {
        "id": "oM1KK1hoUr1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraer el archivo zip"
      ],
      "metadata": {
        "id": "WQNavL28_3jK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from zipfile import ZipFile \n",
        "import pandas as pd\n",
        "# pd.options.mode.chained_assignment = None\n",
        "\n",
        "archivo = \"/content/data/creditcard.zip\"\n",
        "\n",
        "print('Extrayendo contenido...') \n",
        "with ZipFile(archivo, 'r') as Zip: \n",
        "    Zip.extractall() \n",
        "    print('Extracción finalizada.') \n",
        "\n",
        "credito = pd.read_csv(\"creditcard.csv\")"
      ],
      "metadata": {
        "id": "8AGYagMwh8GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito.head()"
      ],
      "metadata": {
        "id": "60RwWl3OAM7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito.describe()"
      ],
      "metadata": {
        "id": "xb2G0chpAP-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Graficamos los que no son fraude\n",
        "time_amount = credito[credito['Class'] == 0][['Time','Amount']].values\n",
        "plt.scatter(time_amount[:,0], time_amount[:,1], \n",
        "            c='green',alpha=0.25,label='Clean')\n",
        "# Graficamos los que sí son fraude\n",
        "time_amount = credito[credito['Class'] == 1][['Time','Amount']].values\n",
        "plt.scatter(time_amount[:,0], time_amount[:,1], \n",
        "            c='red',label='Fraud',marker='x')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Amount vs fraud')\n",
        "plt.xlabel('Time', fontsize=16)\n",
        "plt.ylabel('Amount', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dId7E_NrAXAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "sns.countplot(x = \"Class\", data = credito)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHQqW8EqAbW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "No_of_frauds = credito[credito[\"Class\"]==1].shape[0]\n",
        "No_of_normals = credito[credito[\"Class\"]==0].shape[0]\n",
        "print(\"Hay {} transacciones normales (clase 0)\".format(No_of_normals))\n",
        "print(\"Hay {} transacciones fraudulentas (clase 1)\".format(No_of_frauds))\n",
        "total = No_of_frauds + No_of_normals\n",
        "pf= (No_of_frauds / total)*100\n",
        "pn= (No_of_normals / total)*100\n",
        "print(\"Porcentaje clase 0 = {}%\".format(np.round(pn,2)))\n",
        "print(\"Porcentaje clase 1 = {}%\".format(np.round(pf,2)))"
      ],
      "metadata": {
        "id": "OaWkLhQvBLKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFExW0e-20l7"
      },
      "source": [
        "### Submuestro\n",
        "\n",
        "Se necesita hacer un submuestreo para balancear las clases\n",
        "\n",
        "* Está claro que la Clase 1 está subrepresentada ya que solo  representa el 0.17% de todo el conjunto de datos. \n",
        "* Si entrenamos nuestro modelo usando este conjunto de datos, el modelo será ineficiente y será entrenado para predecir solo la Clase 0 porque no tendrá suficientes datos de entrenamiento.\n",
        "* Podemos obtener una alta exactitud al probar el modelo, pero no debemos confundirnos con esto porque nuestro conjunto de datos no tiene datos de prueba equilibrados. Por lo tanto, tenemos que confiar en el recall que se basa en TP y FP.\n",
        "* En los casos en que tengamos datos asimétricos, agregar datos adicionales de la característica subrepresentada (sobremuestreo) es una opción, mediante la modelación de la distribución de los datos. Por ahora no tenemos esa opción, así que tendremos que recurrir al submuestreo.\n",
        "* El submuestreo del conjunto de datos implica mantener todos nuestros datos subrepresentados (Clase 1) mientras se muestrea el mismo número de características de la Clase 0 para crear un nuevo conjunto de datos que comprenda una representación igual de ambas clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MucsJV0r20l7"
      },
      "source": [
        "Obtenemos un conjunto de datos más balanceado que contenga el doble de instancias no fraudulentas respecto a las fraudulentas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4OPAV8M20l8"
      },
      "outputs": [],
      "source": [
        "# lista los índices de fraude del data set completo\n",
        "fraud_idxs = credito[credito[\"Class\"]==1].index.to_list()\n",
        "\n",
        "# lista de índices normales del data set completo\n",
        "normal_idxs = credito[credito[\"Class\"]==0].index.to_list()\n",
        "\n",
        "# seleccionamos aleatoriamente el doble de índices de transacciones normales que de normales\n",
        "random_normal_idxs = np.random.choice(normal_idxs, No_of_frauds*2, replace= False)\n",
        "\n",
        "# concatenamos los índices fraudulentos y normales y creamos el dataframe sub-sampleado\n",
        "undersampled_indices = np.concatenate([fraud_idxs, random_normal_idxs])\n",
        "undersampled_data = credito.iloc[undersampled_indices, :]\n",
        "\n",
        "print(f\"Fraude: {len(fraud_idxs)}, Normales: {len(random_normal_idxs)}\")\n",
        "undersampled_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Wrm6M620l8"
      },
      "source": [
        "Comprobemos que los datos quedaron balanceados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TRLcfkS20l9"
      },
      "outputs": [],
      "source": [
        "No_of_frauds_sampled = len(undersampled_data[undersampled_data[\"Class\"]== 1])\n",
        "\n",
        "No_of_normals_sampled = len(undersampled_data[undersampled_data[\"Class\"]== 0])\n",
        "\n",
        "print(\"Número de transacciones normales (clase 0): \", No_of_normals_sampled)\n",
        "print(\"Número de transacciones fraudulentas (clase 1): \", No_of_frauds_sampled)\n",
        "total_sampled = No_of_frauds_sampled + No_of_normals_sampled\n",
        "print(\"Número total de instancias: \", total_sampled)\n",
        "\n",
        "Fraud_percent_sampled = (No_of_frauds_sampled / total_sampled)*100\n",
        "Normal_percent_sampled = (No_of_normals_sampled / total_sampled)*100\n",
        "print(f\"Porcentaje clase 0: {round(Normal_percent_sampled,2)}\")\n",
        "print(f\"Porcentaje clase 1: {round(Normal_percent_sampled,2)}\")\n",
        "\n",
        "count_sampled = pd.value_counts(undersampled_data[\"Class\"], sort= True)\n",
        "count_sampled.plot(kind= 'bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quitamos las columnas \"Time\" y \"Amount\"\n",
        "undersampled_data.drop([\"Time\"], axis= 1,inplace=True)"
      ],
      "metadata": {
        "id": "_7a2FuivMYhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_PjO_td20l9"
      },
      "source": [
        "### Oversampling\n",
        "\n",
        "Ahora haremos un proceso llamado [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/abs/1106.1813)\n",
        "\n",
        "\n",
        "Para ello necesitamos instalar la librería de _aprendizaje desequilibrado_ ``imbalanced-learn`` de Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qa_Vb4NP20l_"
      },
      "outputs": [],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos imprimir información sobre el módulo"
      ],
      "metadata": {
        "id": "ZuEXCTrtugUW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4fPH1Bd20mA"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "print(imblearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaNpF9Cu20mB"
      },
      "source": [
        "Obtenemos la matriz de datos $X$ y el vector de clases $y$ correspondiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fWtfSkU20mB"
      },
      "outputs": [],
      "source": [
        "X = undersampled_data.loc[:, undersampled_data.columns != \"Class\"].values\n",
        "y = undersampled_data.loc[:, undersampled_data.columns == \"Class\"].values\n",
        "\n",
        "print(f\"Matriz de features: {X.shape}\")\n",
        "print(f\"Matriz de etiquetas: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF4zrMIG20mC"
      },
      "source": [
        "Hagamos el proceso de sobre-muestreo [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qfmmO0By20mC"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "oversample = SMOTE()\n",
        "X_oversampled, y_oversampled = oversample.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG7Hf5ix20mD"
      },
      "source": [
        "Verifiquemos la cantidad de datos ahora"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(f\"Matriz de features: {X_oversampled.shape}\")\n",
        "print(f\"Matriz de etiquetas: {y_oversampled.shape}\")\n",
        "\n",
        "print(Counter(y_oversampled))"
      ],
      "metadata": {
        "id": "NRujZ0ltPzEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb2gdqXw20mH"
      },
      "source": [
        "### Crear el conjunto de entrenamiento y prueba\n",
        "\n",
        "Separamos los datos en datos de entrenamiento (75%) y prueba (25%) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3loC9tl20mH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, \n",
        "                                                    test_size = 0.25, \n",
        "                                                    random_state = 359)\n",
        "\n",
        "print(\"The split of the under_sampled data is as follows\")\n",
        "print(\"X_train: \", len(X_train))\n",
        "print(\"X_test: \", len(X_test))\n",
        "print(\"y_train: \", len(y_train))\n",
        "print(\"y_test: \", len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTSJsp2K20mB"
      },
      "source": [
        "### Re-escalemos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqtPP2k520mB"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "sc = preprocessing.StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5GqWW6Q20mH"
      },
      "source": [
        "⭕ Elige una SVM y entrénalo con un conjunto de parámetros de tu elección. Obtener el accuracy usando el método `score` del clasificador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekwgZfiG20mH"
      },
      "outputs": [],
      "source": [
        "classifier = SVC(C=1, kernel= 'rbf', random_state=0, gamma='scale')\n",
        "classifier.fit(X_train, y_train)\n",
        "classifier.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp_YhOUu20mI"
      },
      "source": [
        "### Prueba el modelo \n",
        "\n",
        "Realiza las predicciones con el conjunto de prueba y bserva la matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTRsqljv20mI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "CM = confusion_matrix(y_test, y_pred)\n",
        "print(CM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos calcular las métricas de rendimiento *manualmente*."
      ],
      "metadata": {
        "id": "2wgQFPGzZMnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = round((CM[1,1]+CM[0,0])/(CM[0,0] + CM[0,1]+CM[1,0] + CM[1,1])*100,3)\n",
        "rec = round(CM[1,1]/(CM[1,0] + CM[1,1])*100,3)\n",
        "\n",
        "print(f\"Accuracy: {acc}\")\n",
        "print(f\"Recall: {rec}\")"
      ],
      "metadata": {
        "id": "5bYk4F11ZMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Calcula también el *F1-score* y el *precision score*"
      ],
      "metadata": {
        "id": "WGQVuXnXZdHd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjrOfFZ9Th4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmyrMl720mK"
      },
      "source": [
        "### Aplica GridSearch para obtener los mejores parámetros para una SVM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJEOf9L320mK"
      },
      "outputs": [],
      "source": [
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
        "              ]\n",
        "\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           n_jobs = -1)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(\"The best accuracy using gridSearch is\", best_accuracy)\n",
        "\n",
        "best_parameters = grid_search.best_params_\n",
        "print(\"The best parameters for using this model is\", best_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfaYAhAK20mL"
      },
      "source": [
        "### Utiliza los mejores parámetros para probar de nuevo tu modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9EpQKyf20mM"
      },
      "outputs": [],
      "source": [
        "classifier_with_best_parameters =  SVC(C= best_parameters[\"C\"], \n",
        "                                       kernel= best_parameters[\"kernel\"], \n",
        "                                       random_state= 0)\n",
        "classifier_with_best_parameters.fit(X_train, y_train)\n",
        "\n",
        "y_pred_best_parameters = classifier_with_best_parameters.predict(X_test)\n",
        "\n",
        "CM2 = confusion_matrix(y_test, y_pred_best_parameters)\n",
        "print(CM2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭕ Calcula las métricas de rendimiento: Accuracy, Recall, F1-score, Precision"
      ],
      "metadata": {
        "id": "rEJwIr5PVbX-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-BBLmTOSbOSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "htKoV-CNfgJA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wgbaCD020mN"
      },
      "source": [
        "### ⭕ Práctica\n",
        "\n",
        "La práctica consiste en dos ejercicios:\n",
        "\n",
        "1. Usa el modelo anterior (**no lo vuelvas a entrenar**) para obtener las predicciones en todos el conjunto de datos original. Reporta las 4 métricas de rendimiento, así como la matriz de confusión. *Hint*: Puedes usar un pipeline para facilitar el proceso.\n",
        "\n",
        "2. Usa el clasificador lineal OLS con el conjunto de datos entrenamiento balanceado usado en la sesión (el de tamaño 1476). Reporta las 4 métricas de rendimiento, así como la matriz de confusión.\n",
        "\n",
        "3. Entrena un nuevo clasificador SVM en todo el conjunto sesgado. \n",
        "\n",
        "    3.1. Separa el conjunto completo en 75% de entrenamiento y 20% de prueba.\n",
        "\n",
        "    3.2. Entrena un nuevo modelo en este nuevo conjunto de entrenamiento y obten las predicciones en el conjunto de prueba. \n",
        "    \n",
        "    3.3 Reporta las 4 métricas de rendimiento, así como la matriz de confusión. \n",
        "    \n",
        "    Puedes usar técnicas de re-escalamiento, gridsearch, selección de features. Puedes usar un pipeline para facilitar el proceso.\n",
        "\n",
        "Redacta una conclusión comparando el desempeño de la parte 1 y la parte 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7y7HAzbbWOKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6moxfCAm20mP"
      },
      "source": [
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}